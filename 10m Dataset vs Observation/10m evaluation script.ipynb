{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1929c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pickle\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import pandas as pd\n",
    "from rasterio.transform import rowcol\n",
    "from zoneinfo import ZoneInfo  \n",
    "\n",
    "\n",
    "# Loading of the ICON 10m windspeed pickle file\n",
    "windspeed_10m_icon_table = pd.read_pickle(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\wind-speed-10m_icon_table.pickle\")\n",
    "\n",
    "# Data cleaning(The remove of duplicated and unik value contains columns)\n",
    "windspeed_10m_icon_table = windspeed_10m_icon_table.loc[:, ~windspeed_10m_icon_table.columns.duplicated()]\n",
    "windspeed_10m_icon_table = windspeed_10m_icon_table.loc[:, windspeed_10m_icon_table.apply(lambda col: col.nunique() > 1, axis=0)]\n",
    "\n",
    "# üîπ Load of the corresponding excel files \n",
    "df_mapping_ICON_Station_ID = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Station_ID_vs_ICON_code.csv\", sep=';')\n",
    "# üîπ Verification of columns availability\n",
    "if not {\"Station_ID\", \"ICON_code\"}.issubset(df_mapping_ICON_Station_ID.columns):\n",
    "    raise ValueError(\"Les colonnes 'Station_ID' et 'ICON_code' sont absentes du fichier.\")\n",
    "# üîπ Create a dict of corresponding{ICON_code: Station_ID}\n",
    "icon_to_station = dict(zip(df_mapping_ICON_Station_ID[\"ICON_code\"].astype(str), df_mapping_ICON_Station_ID[\"Station_ID\"]))\n",
    "# üîπ Subtitute the name of the columns instead of index\n",
    "windspeed_10m_icon_table.rename(columns=icon_to_station, inplace=True)\n",
    "windspeed_10m_icon_table.index = windspeed_10m_icon_table.index.tz_localize(\"UTC\")\n",
    "\n",
    "#Loading of the observed 10m windspeed pickle file\n",
    "obs_10m_table = pd.read_pickle(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\wind-speed-10m_obs_table.pickle\")\n",
    "print(\"Before shift\")\n",
    "print(obs_10m_table[\"858148\"])\n",
    "\n",
    "#Set the time zone to UTC\n",
    "station_SASSCAL_list = [\n",
    "    \"39711\", \"46943\", \"47066\", \"361100\", \"858246\", \"21\", \"22\", \"23\", \"24\", \"25\",\n",
    "    \"67581\", \"67583\", \"67585\", \"67591\", \"67593\", \"68024\", \"68026\", \"68030\", \"68038\",\n",
    "    \"68148\", \"68151\", \"68226\", \"68320\", \"68325\", \"68328\", \"101\", \"102\", \"103\", \"104\",\n",
    "    \"105\", \"106\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\",\n",
    "    \"4230\", \"4756\", \"4806\", \"8893\", \"31195\", \"31196\", \"31197\", \"31198\", \"31199\",\n",
    "    \"31200\", \"31202\", \"31203\", \"31204\", \"31205\", \"31206\", \"31207\", \"31209\", \"31210\",\n",
    "    \"31212\", \"31213\", \"31214\", \"31215\", \"31216\", \"52121\", \"58557\", \"64243\", \"64258\",\n",
    "    \"65934\", \"65941\", \"67134\", \"67135\", \"74229\", \"74714\", \"75823\", \"80493\", \"80498\",\n",
    "    \"E7624\", \"E7625\", \"E7626\", \"E7627\", \"E7628\", \"E7629\", \"E7630\", \"E7631\",\n",
    "    \"E9126\", \"E9127\", \"361096\", \"361097\", \"361098\", \"361099\",\n",
    "    \"511942\", \"511943\", \"511944\",\n",
    "    \"858576\", \"858577\", \"858580\", \"858581\", \"858583\", \"858585\", \"858590\", \"858596\",\n",
    "    \"856134\", \"858148\", \"858594\"\n",
    "]\n",
    "E_cols = [\"E7624\", \"E7625\", \"E7626\", \"E7627\", \"E7628\", \"E7629\", \"E7630\", \"E7631\", \"E9126\", \"E9127\"]\n",
    "utc_plus_1_cols = [\"46943\", \"47066\", \"361100\", \"858246\"]\n",
    "remains_sasscal_cols = [col for col in station_SASSCAL_list if col not in utc_plus_1_cols and col not in E_cols]\n",
    "utc_plus_2_cols = [col for col in remains_sasscal_cols if col in obs_10m_table.columns]\n",
    "remains_obs_all = [col for col in obs_10m_table.columns if col not in utc_plus_1_cols and col not in utc_plus_2_cols]\n",
    "\n",
    "windspeed_10m_obs_table = pd.DataFrame()\n",
    "\n",
    "# For station already in UTC\n",
    "for col in remains_obs_all:\n",
    "    if col in obs_10m_table.columns:\n",
    "        s = obs_10m_table[col].copy()\n",
    "        s.index = s.index.tz_localize(\"UTC\")\n",
    "        windspeed_10m_obs_table[col] = s\n",
    "\n",
    "# For station in UTC+1 (like l'Angola)\n",
    "for col in utc_plus_1_cols:\n",
    "    if col in obs_10m_table.columns:\n",
    "        s = obs_10m_table[col].copy()\n",
    "        s.index = s.index.tz_localize(\"Africa/Luanda\").tz_convert(\"UTC\")\n",
    "        windspeed_10m_obs_table[col] = s\n",
    "\n",
    "# For station in UTC+2 (like l'Afrique du Sud)\n",
    "for col in utc_plus_2_cols:\n",
    "    if col in obs_10m_table.columns:\n",
    "        s = obs_10m_table[col].copy()\n",
    "        s.index = s.index.tz_localize(\"Africa/Johannesburg\").tz_convert(\"UTC\")\n",
    "        windspeed_10m_obs_table[col] = s      \n",
    "print(\"After shift\")\n",
    "print(windspeed_10m_obs_table[\"858148\"])\n",
    "\n",
    "#End of time zone setting\n",
    "\n",
    "#The remove of the implausible data\n",
    "windspeed_10m_obs_table = windspeed_10m_obs_table.where((windspeed_10m_obs_table >= 0) & (windspeed_10m_obs_table <= 40), other=pd.NA)\n",
    "# üîπDefinition of NaN % limit to delete column\n",
    "threshold = 0.70\n",
    "# üîπ Supprimer les colonnes o√π PLUS DE `threshold` % des valeurs sont NaN\n",
    "windspeed_10m_obs_table = windspeed_10m_obs_table.dropna(axis=1, thresh=int((1 - threshold) * len(windspeed_10m_obs_table)))\n",
    "\n",
    "\n",
    "# ERA5 Start here\n",
    "stations = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Stationlat&lon_new.csv\" , sep=';')\n",
    "\n",
    "ERA5_Wind_2017_10m = nc.Dataset(r\"D:\\Wascal_2023-2025\\Thesis\\2025-04-14\\wind_speed\\43df5441fac8134c5e81bd3aa0c48fb0\\data_stream-oper_stepType-instant.nc\")\n",
    "ERA5_Wind_2018_10m = nc.Dataset(r\"D:\\Wascal_2023-2025\\Thesis\\2025-04-14\\wind_speed\\f4cdecdedec5898827f229a7fb114bd5\\data_stream-oper_stepType-instant.nc\")\n",
    "ERA5_Wind_2019_10m = nc.Dataset(r\"D:\\Wascal_2023-2025\\Thesis\\2025-04-14\\wind_speed\\c832a1ecc417cc0e2e0a31ebed19cef6\\data_stream-oper_stepType-instant.nc\")\n",
    "wind_2017_u10 = ERA5_Wind_2017_10m.variables['u10'][:]\n",
    "wind_2017_v10 = ERA5_Wind_2017_10m.variables['v10'][:]\n",
    "wind_2018_u10 = ERA5_Wind_2018_10m.variables['u10'][:]\n",
    "wind_2018_v10 = ERA5_Wind_2018_10m.variables['v10'][:]\n",
    "wind_2019_u10 = ERA5_Wind_2019_10m.variables['u10'][:]\n",
    "wind_2019_v10 = ERA5_Wind_2019_10m.variables['v10'][:]\n",
    "\n",
    "wind_ERA5_list = []\n",
    "lats_2017 = ERA5_Wind_2017_10m['latitude'][:]\n",
    "lons_2017 = ERA5_Wind_2017_10m['longitude'][:]\n",
    "lats_2018 = ERA5_Wind_2018_10m['latitude'][:]\n",
    "lons_2018 = ERA5_Wind_2018_10m['longitude'][:]\n",
    "lats_2019 = ERA5_Wind_2019_10m['latitude'][:]\n",
    "lons_2019 = ERA5_Wind_2019_10m['longitude'][:]\n",
    "for _, row in stations.iterrows():\n",
    "    lat_idx_2017 = np.abs(lats_2017 - row['latitude']).argmin()\n",
    "    lon_idx_2017 = np.abs(lons_2017 - row['longitude']).argmin()\n",
    "    lat_idx_2018 = np.abs(lats_2018 - row['latitude']).argmin()\n",
    "    lon_idx_2018 = np.abs(lons_2018 - row['longitude']).argmin()\n",
    "    lat_idx_2019 = np.abs(lats_2019 - row['latitude']).argmin()\n",
    "    lon_idx_2019 = np.abs(lons_2019 - row['longitude']).argmin()\n",
    "    wind_2017_10m = np.sqrt(((wind_2017_u10[:, lat_idx_2017, lon_idx_2017])**2) + ((wind_2017_v10[:, lat_idx_2017, lon_idx_2017])**2))\n",
    "    wind_2018_10m = np.sqrt(((wind_2018_u10[:, lat_idx_2018, lon_idx_2018])**2) + ((wind_2018_v10[:, lat_idx_2018, lon_idx_2018])**2))\n",
    "    wind_2019_10m = np.sqrt(((wind_2019_u10[:, lat_idx_2019, lon_idx_2019])**2) + ((wind_2019_v10[:, lat_idx_2019, lon_idx_2019])**2))\n",
    "    wind_2017_to_2019_ERA5_10m = np.concatenate([wind_2017_10m, wind_2018_10m, wind_2019_10m], axis=0)\n",
    "    wind_ERA5_list.append(pd.Series(wind_2017_to_2019_ERA5_10m, name=row['station']))\n",
    "    \n",
    "wind_ERA5 = pd.concat(wind_ERA5_list, axis=1)\n",
    "start_time = \"2017-01-01 00:00:00\"\n",
    "wind_ERA5.index = pd.date_range(start=start_time, periods=wind_ERA5.shape[0], freq=\"h\").tz_localize(\"UTC\")\n",
    "print(wind_ERA5['858148'])\n",
    "\n",
    "# Extraction of ERA5 WM\n",
    "WM_Station = ['WM01', 'WM02', 'WM03', 'WM05', 'WM06', 'WM07', 'WM08', 'WM09', 'WM10', 'WM11', 'WM12', 'WM13', 'WM14', 'WM15', 'WM16', 'WM17', 'WM18', 'WM19']\n",
    "windspeed_10m_ERA5_WM = wind_ERA5[WM_Station]\n",
    "\n",
    "#ERA5_GWA start here\n",
    "ERA5_wind_speed_10m_mean_2008to2017_southern_Africa = nc.Dataset(r\"D:\\Wascal_2023-2025\\Thesis\\2025-04-14\\wind_speed\\ERA5_wind_speed_10m_mean_2008to2017_southern_Africa.nc\")\n",
    "lats_ERA5 = ERA5_wind_speed_10m_mean_2008to2017_southern_Africa.variables['latitude'][:]\n",
    "lons_ERA5 = ERA5_wind_speed_10m_mean_2008to2017_southern_Africa.variables['longitude'][:]\n",
    "wind_mean_ERA5 = ERA5_wind_speed_10m_mean_2008to2017_southern_Africa.variables['si10'][0, :, :]  # (time, lat, lon)\n",
    "\n",
    "# === √âtape 1 : Load of CSV files of stations carateristics\n",
    "stations = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Stationlat&lon_new.csv\" , sep=';')\n",
    "# === √âtape 3 : Nearest grid finding\n",
    "def get_wind_value(lon, lat):\n",
    "    lat_idx = np.abs(lats_ERA5 - lat).argmin()\n",
    "    lon_idx = np.abs(lons_ERA5 - lon).argmin()\n",
    "    return float(wind_mean_ERA5[lat_idx, lon_idx])  # Convertir en float simple\n",
    "\n",
    "# === √âtape 4 : Application on every stations\n",
    "stations['wind_mean_10m_ERA5'] = stations.apply(lambda row: get_wind_value(row['longitude'], row['latitude']), axis=1)\n",
    "\n",
    "# === Load of raster GWA\n",
    "rds = rxr.open_rasterio(r\"C:\\Users\\LENOVO\\Downloads\\wind_speed_cog_10m.tif\",masked=True).squeeze()\n",
    "\n",
    "# Use of xarray for nesrest\n",
    "rds = rds.sortby(\"y\")\n",
    "\n",
    "# Verification\n",
    "print(\"üìê Dimensions raster :\", rds.dims)  # ('y', 'x') ‚Äî bon !\n",
    "print(\"üß≠ Coordonn√©es disponibles :\", list(rds.coords))  # ['x', 'y']\n",
    "\n",
    "# === Nearest methods\n",
    "interpolated = rds.interp(\n",
    "    x=(\"points\", stations[\"longitude\"].values),\n",
    "    y=(\"points\", stations[\"latitude\"].values),\n",
    "    method=\"nearest\"\n",
    ")\n",
    "\n",
    "# === Ajouter la colonne au tableau\n",
    "stations[\"wind_mean_10m_GWA_xarray_nearest\"] = interpolated.values\n",
    "\n",
    "stations.to_excel(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Stations_ERA5_GWA_mean_xarray_nearest.xlsx\", index=False)\n",
    "stations['scaling_factor'] = stations['wind_mean_10m_GWA_xarray_nearest'] / stations['wind_mean_10m_ERA5']\n",
    "stations.to_excel(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Station_scaling_ERA5_GWA_array_nearest.xlsx\", index=False)\n",
    "print(\"‚úÖ Nearest methode avec xarray termin√©e !\")        \n",
    "\n",
    "wind_ERA5_GWA_list = []\n",
    "\n",
    "for _, row in stations.iterrows():\n",
    "    station_code = row['station']\n",
    "    if station_code in wind_ERA5.columns:\n",
    "        wind_ts = wind_ERA5[station_code]\n",
    "        wind_correction = wind_ts * row['scaling_factor']\n",
    "        wind_ERA5_GWA_list.append(pd.Series(wind_correction, name=station_code))\n",
    "\n",
    "# Fusionner les s√©ries en un DataFrame\n",
    "wind_ERA5_GWA = pd.concat(wind_ERA5_GWA_list, axis=1)\n",
    "\n",
    "# Ajouter une index temporel\n",
    "start_time = \"2017-01-01 00:00:00\"\n",
    "wind_ERA5_GWA.index = pd.date_range(start=start_time, periods=wind_ERA5_GWA.shape[0], freq=\"h\").tz_localize(\"UTC\")\n",
    "print(wind_ERA5_GWA['858148'])\n",
    "#extraire les WM de ERA5\n",
    "windspeed_10m_ERA5_GWA_WM = wind_ERA5_GWA[WM_Station]\n",
    "\n",
    "# üîπ Find identic column\n",
    "common_stations = list(set(windspeed_10m_obs_table.columns) & set(windspeed_10m_icon_table.columns) & set(wind_ERA5.columns) & set(wind_ERA5_GWA.columns))\n",
    "# üîπ Filtrer les DataFrames pour ne garder que les stations communes\n",
    "windspeed_10m_obs_table = windspeed_10m_obs_table[common_stations]\n",
    "windspeed_10m_icon_table = windspeed_10m_icon_table[common_stations]\n",
    "windspeed_10m_ERA5_table = wind_ERA5[common_stations]\n",
    "windspeed_10m_ERA5_GWA_table = wind_ERA5_GWA[common_stations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ICON-LAM and Observed data Dict creation\n",
    "obs_dict = {}   # Contiendra les donn√©es d'observation (WS_10_obs)\n",
    "icon_dict = {}  # Contiendra les donn√©es simul√©es ICON (WS_10_ICON)\n",
    "\n",
    "#  Conversion of dataframe into dict\n",
    "for station in windspeed_10m_obs_table.columns:\n",
    "    obs_dict[station] = pd.DataFrame({\"WS_10_obs\": windspeed_10m_obs_table[station]})\n",
    "\n",
    "for station in windspeed_10m_icon_table.columns:\n",
    "    icon_dict[station] = pd.DataFrame({\"WS_10_ICON\": windspeed_10m_icon_table[station]})\n",
    "\n",
    "#  Station information loading\n",
    "station_info = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Station_ID_vs_ICON_code & lat_lon_Label.csv\", sep=';')\n",
    "\n",
    "required_columns = {\"Station_ID\", \"longitude\", \"latitude\", \"label\"}\n",
    "if not required_columns.issubset(station_info.columns):\n",
    "    raise ValueError(\"Les colonnes 'Station_ID', 'longitude', 'latitude', 'label' sont absentes du fichier CSV.\")\n",
    "\n",
    "station_meta = station_info.set_index(\"Station_ID\")[[\"longitude\", \"latitude\", \"label\"]].to_dict(orient=\"index\")\n",
    "\n",
    "# dict configuration\n",
    "for station in obs_dict.keys():\n",
    "    if station in station_meta:\n",
    "        obs_dict[station][\"Station_ID\"] = station\n",
    "        obs_dict[station][\"longitude\"] = station_meta[station][\"longitude\"]\n",
    "        obs_dict[station][\"latitude\"] = station_meta[station][\"latitude\"]\n",
    "        obs_dict[station][\"label\"] = station_meta[station][\"label\"]\n",
    "\n",
    "for station in icon_dict.keys():\n",
    "    if station in station_meta:\n",
    "        icon_dict[station][\"Station_ID\"] = station\n",
    "        icon_dict[station][\"longitude\"] = station_meta[station][\"longitude\"]\n",
    "        icon_dict[station][\"latitude\"] = station_meta[station][\"latitude\"]\n",
    "        icon_dict[station][\"label\"] = station_meta[station][\"label\"]\n",
    "\n",
    "\n",
    "# ERA5 and ERA5_GWA dict creation\n",
    "ERA5_dict = {}   # Contiendra les donn√©es d'observation (WS_10_ERA5)\n",
    "ERA5_GWA_dict = {}   # Contiendra les donn√©es d'observation (WS_10_ERA5_GWA)\n",
    "# üîπ Convertir les DataFrames en dictionnaires bas√©s sur les colonnes actuelles (stations)\n",
    "for station in windspeed_10m_ERA5_table.columns:\n",
    "    ERA5_dict[station] = pd.DataFrame({\"WS_10_ERA5\": windspeed_10m_ERA5_table[station]})\n",
    "\n",
    "for station in windspeed_10m_ERA5_GWA_table.columns:\n",
    "    ERA5_GWA_dict[station] = pd.DataFrame({\"WS_10_ERA5_GWA\": windspeed_10m_ERA5_GWA_table[station]})\n",
    "\n",
    "# üîπ Ajouter les m√©tadonn√©es √† chaque station dans les dictionnaires\n",
    "for station in ERA5_dict.keys():\n",
    "    if station in station_meta:\n",
    "        ERA5_dict[station][\"Station_ID\"] = station\n",
    "        ERA5_dict[station][\"longitude\"] = station_meta[station][\"longitude\"]\n",
    "        ERA5_dict[station][\"latitude\"] = station_meta[station][\"latitude\"]\n",
    "        ERA5_dict[station][\"label\"] = station_meta[station][\"label\"]\n",
    "        \n",
    "for station in ERA5_GWA_dict.keys():\n",
    "    if station in station_meta:\n",
    "        ERA5_GWA_dict[station][\"Station_ID\"] = station\n",
    "        ERA5_GWA_dict[station][\"longitude\"] = station_meta[station][\"longitude\"]\n",
    "        ERA5_GWA_dict[station][\"latitude\"] = station_meta[station][\"latitude\"]\n",
    "        ERA5_GWA_dict[station][\"label\"] = station_meta[station][\"label\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Initialiser un dictionnaire pour stocker les r√©sultats ICON\n",
    "metrics_ICON_dict = {}\n",
    "\n",
    "# üîπ Calculer les m√©triques pour chaque station\n",
    "for station in obs_dict.keys():\n",
    "    if station in icon_dict:  # V√©rifier que la station est pr√©sente dans les deux dictionnaires\n",
    "        obs_data = obs_dict[station][\"WS_10_obs\"].dropna()  # Supprimer les NaN\n",
    "        icon_data = icon_dict[station][\"WS_10_ICON\"].dropna()  # Supprimer les NaN\n",
    "\n",
    "        # üîπ Aligner les donn√©es en fonction de l'index (temps)\n",
    "        obs_data.name = \"WS_10_obs\"\n",
    "        icon_data.name = \"WS_10_ICON\"\n",
    "        merged_df_ICON = pd.concat([obs_data, icon_data], axis=1, join=\"inner\")\n",
    "\n",
    "        if not merged_df_ICON.empty:\n",
    "            mae = np.mean(np.abs(merged_df_ICON[\"WS_10_ICON\"] - merged_df_ICON[\"WS_10_obs\"]))  # Mean Absolute Error\n",
    "            me = np.mean(merged_df_ICON[\"WS_10_ICON\"] - merged_df_ICON[\"WS_10_obs\"])  # Mean Error\n",
    "                        \n",
    "            # üîπ Pearson r (calcul√© manuellement selon la formule souhait√©e)\n",
    "            O = merged_df_ICON[\"WS_10_obs\"].values\n",
    "            M = merged_df_ICON[\"WS_10_ICON\"].values  # 2·µâ colonne du mod√®le (ICON, ERA5 ou ERA5_GWA)\n",
    "\n",
    "            O_bar = np.mean(O)\n",
    "            M_bar = np.mean(M)\n",
    "            numerateur = np.sum((M - M_bar) * (O - O_bar))\n",
    "            denominateur = np.sqrt(np.sum((M - M_bar)**2)) * np.sqrt(np.sum((O - O_bar)**2))\n",
    "            pearson_r = numerateur / denominateur if denominateur != 0 else np.nan\n",
    "            \n",
    "            \n",
    "            hist_obs, bin_edges = np.histogram(merged_df_ICON[\"WS_10_obs\"], bins=20, density=True)\n",
    "            hist_icon, _ = np.histogram(merged_df_ICON[\"WS_10_ICON\"], bins=bin_edges, density=True)\n",
    "            pss = np.sum(np.minimum(hist_obs, hist_icon)) * np.diff(bin_edges).mean()\n",
    "\n",
    "            # üîπ Stocker les r√©sultats\n",
    "            metrics_ICON_dict[station] = {\n",
    "                \"Station_ID\": station,\n",
    "                \"longitude\": obs_dict[station][\"longitude\"].iloc[0],\n",
    "                \"latitude\": obs_dict[station][\"latitude\"].iloc[0],\n",
    "                \"label\": obs_dict[station][\"label\"].iloc[0],\n",
    "                \"MAE\": mae,\n",
    "                \"ME\": me,\n",
    "                \"Pearson r\": pearson_r,\n",
    "                \"PSS\": pss\n",
    "            }\n",
    "\n",
    "# üîπ Convertir en DataFrame pour affichage et sauvegarde\n",
    "metrics_ICON_df = pd.DataFrame.from_dict(metrics_ICON_dict, orient=\"index\")\n",
    "# üîπ Sauvegarder le DataFrame en CSV pour utilisation future (optionnel)\n",
    "metrics_ICON_df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\Metrics\\metrics_10m_ICON_LAM_results.csv\", index=False)\n",
    "\n",
    "\n",
    "# üîπ Initialiser un dictionnaire pour stocker les r√©sultats ERA5\n",
    "metrics_ERA5_dict = {}\n",
    "\n",
    "# üîπ Calculer les m√©triques pour chaque station\n",
    "for station in obs_dict.keys():\n",
    "    if station in ERA5_dict:  # V√©rifier que la station est pr√©sente dans les deux dictionnaires\n",
    "        obs_data = obs_dict[station][\"WS_10_obs\"].dropna()  # Supprimer les NaN\n",
    "        ERA5_data = ERA5_dict[station][\"WS_10_ERA5\"].dropna()  # Supprimer les NaN\n",
    "\n",
    "        # üîπ Aligner les donn√©es en fonction de l'index (temps)\n",
    "        obs_data.name = \"WS_10_obs\"\n",
    "        ERA5_data.name = \"WS_10_ERA5\"\n",
    "        merged_df_ERA5 = pd.concat([obs_data, ERA5_data], axis=1, join=\"inner\")\n",
    "\n",
    "        if not merged_df_ERA5.empty:\n",
    "            mae = np.mean(np.abs(merged_df_ERA5[\"WS_10_ERA5\"] - merged_df_ERA5[\"WS_10_obs\"]))  # Mean Absolute Error\n",
    "            me = np.mean(merged_df_ERA5[\"WS_10_ERA5\"] - merged_df_ERA5[\"WS_10_obs\"])  # Mean Error\n",
    "            \n",
    "            # üîπ Pearson r (calcul√© manuellement selon la formule souhait√©e)\n",
    "            O = merged_df_ERA5[\"WS_10_obs\"].values\n",
    "            M = merged_df_ERA5[\"WS_10_ERA5\"].values  # 2·µâ colonne du mod√®le (ICON, ERA5 ou ERA5_GWA)\n",
    "\n",
    "            O_bar = np.mean(O)\n",
    "            M_bar = np.mean(M)\n",
    "            numerateur = np.sum((M - M_bar) * (O - O_bar))\n",
    "            denominateur = np.sqrt(np.sum((M - M_bar)**2)) * np.sqrt(np.sum((O - O_bar)**2))\n",
    "            pearson_r = numerateur / denominateur if denominateur != 0 else np.nan\n",
    "\n",
    "            \n",
    "            hist_obs, bin_edges = np.histogram(merged_df_ERA5[\"WS_10_obs\"], bins=20, density=True)\n",
    "            hist_icon, _ = np.histogram(merged_df_ERA5[\"WS_10_ERA5\"], bins=bin_edges, density=True)\n",
    "            pss = np.sum(np.minimum(hist_obs, hist_icon)) * np.diff(bin_edges).mean()\n",
    "\n",
    "            # üîπ Stocker les r√©sultats\n",
    "            metrics_ERA5_dict[station] = {\n",
    "                \"Station_ID\": station,\n",
    "                \"longitude\": obs_dict[station][\"longitude\"].iloc[0],\n",
    "                \"latitude\": obs_dict[station][\"latitude\"].iloc[0],\n",
    "                \"label\": obs_dict[station][\"label\"].iloc[0],\n",
    "                \"MAE\": mae,\n",
    "                \"ME\": me,\n",
    "                \"Pearson r\": pearson_r,\n",
    "                \"PSS\": pss\n",
    "            }\n",
    "\n",
    "# üîπ Convertir en DataFrame pour affichage et sauvegarde\n",
    "metrics_ERA5_df = pd.DataFrame.from_dict(metrics_ERA5_dict, orient=\"index\")\n",
    "# üîπ Sauvegarder le DataFrame en CSV pour utilisation future (optionnel)\n",
    "metrics_ERA5_df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\Metrics\\metrics_10m_ERA5_results.csv\", index=False)\n",
    "\n",
    "\n",
    "# üîπ Initialiser un dictionnaire pour stocker les r√©sultats ERA5_GWA\n",
    "metrics_ERA5_GWA_dict = {}\n",
    "\n",
    "# üîπ Calculer les m√©triques pour chaque station\n",
    "for station in obs_dict.keys():\n",
    "    if station in ERA5_GWA_dict:  # V√©rifier que la station est pr√©sente dans les deux dictionnaires\n",
    "        obs_data = obs_dict[station][\"WS_10_obs\"].dropna()  # Supprimer les NaN\n",
    "        ERA5_GWA_data = ERA5_GWA_dict[station][\"WS_10_ERA5_GWA\"].dropna()  # Supprimer les NaN\n",
    "\n",
    "        # üîπ Aligner les donn√©es en fonction de l'index (temps)\n",
    "        obs_data.name = \"WS_10_obs\"\n",
    "        ERA5_GWA_data.name = \"WS_10_ERA5_GWA\"\n",
    "        merged_df_ERA5_GWA = pd.concat([obs_data, ERA5_GWA_data], axis=1, join=\"inner\")\n",
    "\n",
    "        if not merged_df_ERA5.empty:\n",
    "            mae = np.mean(np.abs(merged_df_ERA5_GWA[\"WS_10_ERA5_GWA\"] - merged_df_ERA5_GWA[\"WS_10_obs\"]))  # Mean Absolute Error\n",
    "            me = np.mean(merged_df_ERA5_GWA[\"WS_10_ERA5_GWA\"] - merged_df_ERA5_GWA[\"WS_10_obs\"])  # Mean Error\n",
    "            \n",
    "            # üîπ Pearson r (calcul√© manuellement selon la formule souhait√©e)\n",
    "            O = merged_df_ERA5_GWA[\"WS_10_obs\"].values\n",
    "            M = merged_df_ERA5_GWA[\"WS_10_ERA5_GWA\"].values  # 2·µâ colonne du mod√®le (ICON, ERA5 ou ERA5_GWA)\n",
    "\n",
    "            O_bar = np.mean(O)\n",
    "            M_bar = np.mean(M)\n",
    "            numerateur = np.sum((M - M_bar) * (O - O_bar))\n",
    "            denominateur = np.sqrt(np.sum((M - M_bar)**2)) * np.sqrt(np.sum((O - O_bar)**2))\n",
    "            pearson_r = numerateur / denominateur if denominateur != 0 else np.nan\n",
    "\n",
    "                        \n",
    "            hist_obs, bin_edges = np.histogram(merged_df_ERA5_GWA[\"WS_10_obs\"], bins=20, density=True)\n",
    "            hist_ERA5_GWA, _ = np.histogram(merged_df_ERA5_GWA[\"WS_10_ERA5_GWA\"], bins=bin_edges, density=True)\n",
    "            pss = np.sum(np.minimum(hist_obs, hist_ERA5_GWA)) * np.diff(bin_edges).mean()\n",
    "\n",
    "            # üîπ Stocker les r√©sultats\n",
    "            metrics_ERA5_GWA_dict[station] = {\n",
    "                \"Station_ID\": station,\n",
    "                \"longitude\": obs_dict[station][\"longitude\"].iloc[0],\n",
    "                \"latitude\": obs_dict[station][\"latitude\"].iloc[0],\n",
    "                \"label\": obs_dict[station][\"label\"].iloc[0],\n",
    "                \"MAE\": mae,\n",
    "                \"ME\": me,\n",
    "                \"Pearson r\": pearson_r,\n",
    "                \"PSS\": pss\n",
    "            }\n",
    "\n",
    "# üîπ Convertir en DataFrame pour affichage et sauvegarde\n",
    "metrics_ERA5_GWA_df = pd.DataFrame.from_dict(metrics_ERA5_GWA_dict, orient=\"index\")\n",
    "# üîπ Sauvegarder le DataFrame en CSV pour utilisation future (optionnel)\n",
    "metrics_ERA5_GWA_df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\Metrics\\metrics_10m_ERA5_GWA_results.csv\", index=False)\n",
    "metrics_ERA5_GWA_df.to_excel(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\Metrics\\metrics_10m_ERA5_GWA_results.xlsx\", index=False)\n",
    "metrics_ERA5_df.to_excel(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\Metrics\\metrics_10m_ERA5_results.xlsx\", index=False)\n",
    "metrics_ICON_df.to_excel(r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\Metrics\\metrics_10m_ICON_LAM_results.xlsx\", index=False)\n",
    "\n",
    "print(\"Metrics ICON_LAM\")\n",
    "print(metrics_ICON_df.head())\n",
    "print(\"Metrics ERA5\")\n",
    "print(metrics_ERA5_df.head())\n",
    "print(\"Metrics ERA5_GWA\")\n",
    "print(metrics_ERA5_GWA_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6494c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_extremes(df, dataset_name):\n",
    "    print(f\"\\nüìä Dataset: {dataset_name}\")\n",
    "    metrics = [\"MAE\", \"ME\", \"Pearson r\", \"PSS\"]\n",
    "\n",
    "    for metric in metrics:\n",
    "        print(f\"\\nüîπ Metric: {metric}\")\n",
    "\n",
    "        # Max value\n",
    "        max_row = df.loc[df[metric].idxmax()]\n",
    "        print(f\"‚¨ÜÔ∏è Highest {metric}:\")\n",
    "        print(max_row.to_string())\n",
    "\n",
    "        # Min value\n",
    "        min_row = df.loc[df[metric].idxmin()]\n",
    "        print(f\"\\n‚¨áÔ∏è Lowest {metric}:\")\n",
    "        print(min_row.to_string())\n",
    "\n",
    "# üì• Apply to each dataset\n",
    "print_extremes(metrics_ICON_df, \"ICON-LAM\")\n",
    "print_extremes(metrics_ERA5_df, \"ERA5\")\n",
    "print_extremes(metrics_ERA5_GWA_df, \"ERA5_GWA\")\n",
    "\n",
    "\n",
    "\n",
    "def count_mae_intervals(df, dataset_name):\n",
    "    print(f\"\\nüìä MAE Intervals for {dataset_name}\")\n",
    "\n",
    "    # D√©finir les intervalles\n",
    "    bins = [0, 1, 2, 4, float('inf')]\n",
    "    labels = [\"[0‚Äì1]\", \"(1‚Äì2]\", \"(2‚Äì4]\", \">4\"]\n",
    "\n",
    "    # Cr√©er une nouvelle colonne avec les intervalles\n",
    "    df[\"MAE_interval\"] = pd.cut(df[\"MAE\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # Compter les occurrences par intervalle\n",
    "    counts = df[\"MAE_interval\"].value_counts().sort_index()\n",
    "\n",
    "    # Afficher les r√©sultats\n",
    "    for label in labels:\n",
    "        print(f\"{label}: {counts.get(label, 0)} stations\")\n",
    "\n",
    "# üì• Appliquer √† chaque dataset\n",
    "count_mae_intervals(metrics_ICON_df, \"ICON-LAM\")\n",
    "count_mae_intervals(metrics_ERA5_df, \"ERA5\")\n",
    "count_mae_intervals(metrics_ERA5_GWA_df, \"ERA5_GWA\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Liste des DataFrames √† traiter\n",
    "metrics_dataset_dfs = {\n",
    "    \"ICON-LAM\": metrics_ICON_df,\n",
    "    \"ERA5\": metrics_ERA5_df,\n",
    "    \"ERA5_GWA\": metrics_ERA5_GWA_df\n",
    "}\n",
    "\n",
    "# üîπ Colonnes √† moyenner\n",
    "metric_columns = [\"MAE\", \"ME\", \"Pearson r\", \"PSS\"]\n",
    "\n",
    "# üîπ Initialiser un tableau de r√©sultats\n",
    "summary_means_dataset = pd.DataFrame(columns=metric_columns)\n",
    "\n",
    "# üîπ Calculer la moyenne pour chaque jeu de donn√©es\n",
    "for name, df in metrics_dataset_dfs.items():\n",
    "    summary_means_dataset.loc[name] = df[metric_columns].mean()\n",
    "\n",
    "# üîπ Afficher le r√©sum√© des moyennes\n",
    "print(\"üìä Metric Average from each dataset  :\")\n",
    "print(summary_means_dataset)\n",
    "\n",
    "# üîπ D√©finir les quantiles que tu veux\n",
    "quantiles = [0.10, 0.20, 0.25, 0.30, 0.40, 0.50, 0.60, 0.70, 0.75, 0.80, 0.90, 0.95]\n",
    "\n",
    "# üîπ Colonnes des m√©triques\n",
    "metrics = [\"MAE\", \"ME\", \"Pearson r\", \"PSS\"]\n",
    "\n",
    "# üîπ Calculer les quantiles globalement (sur toutes les stations)\n",
    "quantile_ICON_df = metrics_ICON_df[metrics].quantile(quantiles)\n",
    "\n",
    "# üîπ Nettoyer l'affichage\n",
    "quantile_ICON_df.index = [f\"{int(q*100)}%\" for q in quantiles]\n",
    "quantile_ICON_df.index.name = \"Quantile\"\n",
    "\n",
    "# üîπ Afficher le tableau\n",
    "print(\"üìä Quantiles globaux pour les m√©triques ICON-LAM :\")\n",
    "print(quantile_ICON_df)\n",
    "\n",
    "\n",
    "# üîπ Colonnes des m√©triques\n",
    "metrics = [\"MAE\", \"ME\", \"Pearson r\", \"PSS\"]\n",
    "\n",
    "# üîπ Calculer les quantiles globalement (sur toutes les stations)\n",
    "quantile_ERA5_df = metrics_ERA5_df[metrics].quantile(quantiles)\n",
    "\n",
    "# üîπ Nettoyer l'affichage\n",
    "quantile_ERA5_df.index = [f\"{int(q*100)}%\" for q in quantiles]\n",
    "quantile_ERA5_df.index.name = \"Quantile\"\n",
    "\n",
    "# üîπ Afficher le tableau\n",
    "print(\"üìä Quantiles globaux pour les m√©triques ERA5 :\")\n",
    "print(quantile_ERA5_df)\n",
    "\n",
    "\n",
    "# üîπ Colonnes des m√©triques\n",
    "metrics = [\"MAE\", \"ME\", \"Pearson r\", \"PSS\"]\n",
    "\n",
    "# üîπ Calculer les quantiles globalement (sur toutes les stations)\n",
    "quantile_ERA5_GWA_df = metrics_ERA5_GWA_df[metrics].quantile(quantiles)\n",
    "\n",
    "# üîπ Nettoyer l'affichage\n",
    "quantile_ERA5_GWA_df.index = [f\"{int(q*100)}%\" for q in quantiles]\n",
    "quantile_ERA5_GWA_df.index.name = \"Quantile\"\n",
    "\n",
    "# üîπ Afficher le tableau\n",
    "print(\"üìä Quantiles globaux pour les m√©triques ERA5_GWA :\")\n",
    "print(quantile_ERA5_GWA_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# === Chargement des donn√©es ===\n",
    "metrics_files = {\n",
    "    \"ICON-LAM\": r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\Metrics\\metrics_10m_ICON_LAM_results.csv\",\n",
    "    \"ERA5\": r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\Metrics\\metrics_10m_ERA5_results.csv\",\n",
    "    \"ERA5_GWA\": r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\Metrics\\metrics_10m_ERA5_GWA_results.csv\"\n",
    "}\n",
    "metrics_data = {name: pd.read_csv(path) for name, path in metrics_files.items()}\n",
    "station_shapes = {\"SASSCALWN\": \"s\", \"TAHMO\": \"^\", \"NCEI\": \"o\"}\n",
    "\n",
    "world = gpd.read_file(\"https://naturalearth.s3.amazonaws.com/10m_cultural/ne_10m_admin_0_countries.zip\")\n",
    "africa_south = world[world[\"NAME\"].isin([\n",
    "    \"South Africa\", \"Namibia\", \"Botswana\", \"Zimbabwe\", \"Mozambique\",\n",
    "    \"Angola\", \"Lesotho\", \"Eswatini\", \"Zambia\"\n",
    "])]\n",
    "\n",
    "# === M√©trique cibl√©e\n",
    "metric = \"MAE\"\n",
    "title = \"Mean Absolute Error (MAE)\"\n",
    "# Plages de valeurs\n",
    "bounds = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "n_colors = len(bounds) - 1\n",
    "\n",
    "# Couleurs correspondantes (autant que d'intervalles)\n",
    "custom_colors = ['#253494', '#41b6c4', '#ffffcc',\n",
    "                 '#fed976', '#f03b20', '#bd0026'][:n_colors]\n",
    "\n",
    "# Colormap personnalis√©e\n",
    "cmap = mcolors.ListedColormap(custom_colors)\n",
    "\n",
    "# === R√©cup√©rer toutes les valeurs (pour une √©chelle coh√©rente)\n",
    "all_values = []\n",
    "\n",
    "\n",
    "for df in metrics_data.values():\n",
    "    all_values.extend(df[metric].dropna().values)\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=cmap.N)\n",
    "\n",
    "# === Cr√©ation des sous-cartes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 20), sharex=True, sharey=True)\n",
    "plt.subplots_adjust(wspace=0.12, bottom=0.4, top=0.98)\n",
    "\n",
    "for ax, (name, df) in zip(axes, metrics_data.items()):\n",
    "    africa_south.plot(ax=ax, color=\"whitesmoke\", edgecolor=\"black\")\n",
    "    for label, shape in station_shapes.items():\n",
    "        subset = df[df[\"label\"] == label]\n",
    "        ax.scatter(\n",
    "            subset[\"longitude\"], subset[\"latitude\"],\n",
    "            c=subset[metric], cmap=cmap, norm=norm,\n",
    "            s=100, marker=shape, edgecolor=\"black\"\n",
    "        )\n",
    "        # üîÅ Graduation personnalis√©e pour latitude\n",
    "    lat_ticks = [-42, -35, -30, -25, -20, -15, -10]  # Valeurs en ¬∞S\n",
    "    lat_labels = [f\"{abs(val)}¬∞S\" for val in lat_ticks]\n",
    "        # üîÅ Graduation personnalis√©e pour longitude\n",
    "    lon_ticks = [10, 15, 20, 25, 30, 35, 40]  # Valeurs en ¬∞E\n",
    "    lon_labels = [f\"{val}¬∞E\" for val in lon_ticks]\n",
    "\n",
    "    \n",
    "    ax.set_title(f\"{name}\", fontsize=20)\n",
    "    ax.set_xticks(lon_ticks)\n",
    "    ax.set_yticks(lat_ticks)\n",
    "    ax.set_xticklabels(lon_labels, fontsize=14)\n",
    "    ax.set_yticklabels(lat_labels, fontsize=14)\n",
    "    # Limiter l'affichage √† la zone g√©ographique cibl√©e\n",
    "    ax.set_xlim(min(lon_ticks), max(lon_ticks))\n",
    "    ax.set_ylim(min(lat_ticks), max(lat_ticks))\n",
    "    ax.set_xlabel(\"Longitude\", fontsize=16)\n",
    "    ax.set_ylabel(\"Latitude\", fontsize=16)\n",
    "\n",
    "# ‚úÖ Barre de couleurs\n",
    "cbar_ax = fig.add_axes([0.2, 0.48, 0.5, 0.02])\n",
    "cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "                    cax=cbar_ax, orientation='horizontal', extend='max')\n",
    "cbar.set_label(\"MAE in [m/s]\", loc='right', fontsize=16)\n",
    "cbar.ax.xaxis.set_label_position('top') \n",
    "cbar.ax.tick_params(labelsize=14)  # ou 16, 18 selon ton besoin\n",
    "\n",
    "    # üîπ L√©gende des r√©seaux\n",
    "legend_elements = [plt.Line2D([0], [0], marker=station_shapes[lab], color='black',\n",
    "                                  linestyle='None', label=lab, markersize=14,\n",
    "                                  markerfacecolor='white', markeredgecolor='black')\n",
    "                       for lab in station_shapes]\n",
    "ax.legend(handles=legend_elements, loc='lower right', frameon=True, fontsize=14)\n",
    "\n",
    "\n",
    "# Sauvegarde\n",
    "save_path = r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\plot\\10m\\Compared_Dataset_MAE_10m.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === M√©trique cibl√©e\n",
    "metric = \"ME\"\n",
    "title = \"Mean  Error (ME)\"\n",
    "# Plages de valeurs\n",
    "bounds = [-4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0,]\n",
    "n_colors = len(bounds) - 1\n",
    "\n",
    "# Couleurs correspondantes (autant que d'intervalles)\n",
    "custom_colors = ['#253494', '#2c7fb8', '#41b6c4', '#a1dab4', '#ffffcc',\n",
    "                 '#fed976', '#feb24c', '#f03b20', '#bd0026'][:n_colors]\n",
    "# Colormap personnalis√©e\n",
    "cmap = plt.get_cmap('RdBu_r')\n",
    "\n",
    "# === R√©cup√©rer toutes les valeurs (pour une √©chelle coh√©rente)\n",
    "all_values = []\n",
    "\n",
    "\n",
    "for df in metrics_data.values():\n",
    "    all_values.extend(df[metric].dropna().values)\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=cmap.N)\n",
    "\n",
    "# === Cr√©ation des sous-cartes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 20), sharex=True, sharey=True)\n",
    "plt.subplots_adjust(wspace=0.12, bottom=0.4, top=0.98)\n",
    "\n",
    "for ax, (name, df) in zip(axes, metrics_data.items()):\n",
    "    africa_south.plot(ax=ax, color=\"whitesmoke\", edgecolor=\"black\")\n",
    "    for label, shape in station_shapes.items():\n",
    "        subset = df[df[\"label\"] == label]\n",
    "        ax.scatter(\n",
    "            subset[\"longitude\"], subset[\"latitude\"],\n",
    "            c=subset[metric], cmap=cmap, norm=norm,\n",
    "            s=100, marker=shape, edgecolor=\"black\"\n",
    "        )\n",
    "        # üîÅ Graduation personnalis√©e pour latitude\n",
    "    lat_ticks = [-42, -35, -30, -25, -20, -15, -10]  # Valeurs en ¬∞S\n",
    "    lat_labels = [f\"{abs(val)}¬∞S\" for val in lat_ticks]\n",
    "        # üîÅ Graduation personnalis√©e pour longitude\n",
    "    lon_ticks = [10, 15, 20, 25, 30, 35, 40]  # Valeurs en ¬∞E\n",
    "    lon_labels = [f\"{val}¬∞E\" for val in lon_ticks]\n",
    "\n",
    "    \n",
    "    ax.set_title(f\"{name}\", fontsize=20)\n",
    "    ax.set_xticks(lon_ticks)\n",
    "    ax.set_yticks(lat_ticks)\n",
    "    ax.set_xticklabels(lon_labels, fontsize=14)\n",
    "    ax.set_yticklabels(lat_labels, fontsize=14)\n",
    "    # Limiter l'affichage √† la zone g√©ographique cibl√©e\n",
    "    ax.set_xlim(min(lon_ticks), max(lon_ticks))\n",
    "    ax.set_ylim(min(lat_ticks), max(lat_ticks))\n",
    "    ax.set_xlabel(\"Longitude\", fontsize=16)\n",
    "    ax.set_ylabel(\"Latitude\", fontsize=16)\n",
    "\n",
    "# ‚úÖ Barre de couleurs\n",
    "cbar_ax = fig.add_axes([0.2, 0.48, 0.5, 0.02])\n",
    "cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "                    cax=cbar_ax, orientation='horizontal', extend = 'both')\n",
    "cbar.set_label(\"ME in [m/s]\", loc='right', fontsize=16)\n",
    "cbar.ax.xaxis.set_label_position('top') \n",
    "cbar.ax.tick_params(labelsize=14)  # ou 16, 18 selon ton besoin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # üîπ L√©gende des r√©seaux\n",
    "legend_elements = [plt.Line2D([0], [0], marker=station_shapes[lab], color='black',\n",
    "                                  linestyle='None', label=lab, markersize=14,\n",
    "                                  markerfacecolor='white', markeredgecolor='black')\n",
    "                       for lab in station_shapes]\n",
    "ax.legend(handles=legend_elements, loc='lower right', frameon=True, fontsize=14)\n",
    "\n",
    "\n",
    "# Sauvegarde\n",
    "save_path = r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\plot\\10m\\Compared_Dataset_ME_10m.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === M√©trique cibl√©e\n",
    "metric = \"Pearson r\"\n",
    "title = \"Pearson Correlation (r)\"\n",
    "# Plages de valeurs\n",
    "bounds = [0.0, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "n_colors = len(bounds) - 1\n",
    "\n",
    "# Couleurs correspondantes (autant que d'intervalles)\n",
    "custom_colors = ['#bd0026', '#f03b20', '#feb24c', '#fed976', '#ffffcc', '#a1dab4', '#41b6c4', '#2c7fb8', '#253494'][:n_colors]\n",
    "\n",
    "cmap = plt.get_cmap('RdYlGn_r')\n",
    "\n",
    "# === R√©cup√©rer toutes les valeurs (pour une √©chelle coh√©rente)\n",
    "all_values = []\n",
    "\n",
    "\n",
    "for df in metrics_data.values():\n",
    "    all_values.extend(df[metric].dropna().values)\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=cmap.N)\n",
    "\n",
    "# === Cr√©ation des sous-cartes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 20), sharex=True, sharey=True)\n",
    "plt.subplots_adjust(wspace=0.12, bottom=0.4, top=0.98)\n",
    "\n",
    "for ax, (name, df) in zip(axes, metrics_data.items()):\n",
    "    africa_south.plot(ax=ax, color=\"whitesmoke\", edgecolor=\"black\")\n",
    "    for label, shape in station_shapes.items():\n",
    "        subset = df[df[\"label\"] == label]\n",
    "        ax.scatter(\n",
    "            subset[\"longitude\"], subset[\"latitude\"],\n",
    "            c=subset[metric], cmap=cmap, norm=norm,\n",
    "            s=100, marker=shape, edgecolor=\"black\"\n",
    "        )\n",
    "        # üîÅ Graduation personnalis√©e pour latitude\n",
    "    lat_ticks = [-42, -35, -30, -25, -20, -15, -10]  # Valeurs en ¬∞S\n",
    "    lat_labels = [f\"{abs(val)}¬∞S\" for val in lat_ticks]\n",
    "        # üîÅ Graduation personnalis√©e pour longitude\n",
    "    lon_ticks = [10, 15, 20, 25, 30, 35, 40]  # Valeurs en ¬∞E\n",
    "    lon_labels = [f\"{val}¬∞E\" for val in lon_ticks]\n",
    "\n",
    "    \n",
    "    ax.set_title(f\"{name}\", fontsize=20)\n",
    "    ax.set_xticks(lon_ticks)\n",
    "    ax.set_yticks(lat_ticks)\n",
    "    ax.set_xticklabels(lon_labels, fontsize=14)\n",
    "    ax.set_yticklabels(lat_labels, fontsize=14)\n",
    "    # Limiter l'affichage √† la zone g√©ographique cibl√©e\n",
    "    ax.set_xlim(min(lon_ticks), max(lon_ticks))\n",
    "    ax.set_ylim(min(lat_ticks), max(lat_ticks))\n",
    "    ax.set_xlabel(\"Longitude\", fontsize=16)\n",
    "    ax.set_ylabel(\"Latitude\", fontsize=16)\n",
    "\n",
    "# ‚úÖ Barre de couleurs\n",
    "cbar_ax = fig.add_axes([0.2, 0.48, 0.5, 0.02])\n",
    "cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "                    cax=cbar_ax, orientation='horizontal')\n",
    "cbar.set_label(\"Pearson_r [-]\", loc='right', fontsize=16)\n",
    "cbar.ax.xaxis.set_label_position('top') \n",
    "cbar.ax.tick_params(labelsize=14)  # ou 16, 18 selon ton besoin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # üîπ L√©gende des r√©seaux\n",
    "legend_elements = [plt.Line2D([0], [0], marker=station_shapes[lab], color='black',\n",
    "                                  linestyle='None', label=lab, markersize=14,\n",
    "                                  markerfacecolor='white', markeredgecolor='black')\n",
    "                       for lab in station_shapes]\n",
    "ax.legend(handles=legend_elements, loc='lower right', frameon=True, fontsize=14)\n",
    "\n",
    "\n",
    "# Sauvegarde\n",
    "save_path = r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\plot\\10m\\Compared_Dataset_Pearson_r_10m.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === M√©trique cibl√©e\n",
    "metric = \"PSS\"\n",
    "title = \"Perkins Skill Score (PSS)\"\n",
    "# Plages de valeurs\n",
    "bounds = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "n_colors = len(bounds) - 1\n",
    "\n",
    "custom_colors = [\n",
    "    '#f0f0f0',  # 0.0 : gris tr√®s clair\n",
    "    '#d9d9d9',  # 0.1 : gris clair\n",
    "    '#ffffcc',  # 0.2 : jaune p√¢le\n",
    "    '#ffeda0',  # 0.3 : jaune doux\n",
    "    '#fed976',  # 0.4 : jaune plus chaud\n",
    "    '#c5dbf0',  # 0.5 : transition vers bleu clair\n",
    "    '#9ecae1',  # 0.6 : bleu doux\n",
    "    '#6baed6',  # 0.7 : bleu mod√©r√©\n",
    "    '#3182bd',  # 0.8 : bleu fonc√©\n",
    "    '#08519c'   # 0.9‚Äì1.0 : bleu profond\n",
    "]\n",
    "\n",
    "# Colormap personnalis√©e\n",
    "cmap = mcolors.ListedColormap(custom_colors)\n",
    "\n",
    "# === R√©cup√©rer toutes les valeurs (pour une √©chelle coh√©rente)\n",
    "all_values = []\n",
    "\n",
    "\n",
    "for df in metrics_data.values():\n",
    "    all_values.extend(df[metric].dropna().values)\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=cmap.N)\n",
    "\n",
    "# === Cr√©ation des sous-cartes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 20), sharex=True, sharey=True)\n",
    "plt.subplots_adjust(wspace=0.12, bottom=0.4, top=0.98)\n",
    "\n",
    "for ax, (name, df) in zip(axes, metrics_data.items()):\n",
    "    africa_south.plot(ax=ax, color=\"whitesmoke\", edgecolor=\"black\")\n",
    "    for label, shape in station_shapes.items():\n",
    "        subset = df[df[\"label\"] == label]\n",
    "        ax.scatter(\n",
    "            subset[\"longitude\"], subset[\"latitude\"],\n",
    "            c=subset[metric], cmap=cmap, norm=norm,\n",
    "            s=100, marker=shape, edgecolor=\"black\"\n",
    "        )\n",
    "        # üîÅ Graduation personnalis√©e pour latitude\n",
    "    lat_ticks = [-42, -35, -30, -25, -20, -15, -10]  # Valeurs en ¬∞S\n",
    "    lat_labels = [f\"{abs(val)}¬∞S\" for val in lat_ticks]\n",
    "        # üîÅ Graduation personnalis√©e pour longitude\n",
    "    lon_ticks = [10, 15, 20, 25, 30, 35, 40]  # Valeurs en ¬∞E\n",
    "    lon_labels = [f\"{val}¬∞E\" for val in lon_ticks]\n",
    "\n",
    "    \n",
    "    ax.set_title(f\"{name}\", fontsize=20)\n",
    "    ax.set_xticks(lon_ticks)\n",
    "    ax.set_yticks(lat_ticks)\n",
    "    ax.set_xticklabels(lon_labels, fontsize=14)\n",
    "    ax.set_yticklabels(lat_labels, fontsize=14)\n",
    "    # Limiter l'affichage √† la zone g√©ographique cibl√©e\n",
    "    ax.set_xlim(min(lon_ticks), max(lon_ticks))\n",
    "    ax.set_ylim(min(lat_ticks), max(lat_ticks))\n",
    "    ax.set_xlabel(\"Longitude\", fontsize=16)\n",
    "    ax.set_ylabel(\"Latitude\", fontsize=16)\n",
    "\n",
    "# ‚úÖ Barre de couleurs\n",
    "cbar_ax = fig.add_axes([0.2, 0.48, 0.5, 0.02])\n",
    "cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "                    cax=cbar_ax, orientation='horizontal')\n",
    "cbar.set_label(\"PSS [-]\", loc='right', fontsize=16)\n",
    "cbar.ax.xaxis.set_label_position('top') \n",
    "cbar.ax.tick_params(labelsize=14)  # ou 16, 18 selon ton besoin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # üîπ L√©gende des r√©seaux\n",
    "legend_elements = [plt.Line2D([0], [0], marker=station_shapes[lab], color='black',\n",
    "                                  linestyle='None', label=lab, markersize=14,\n",
    "                                  markerfacecolor='white', markeredgecolor='black')\n",
    "                       for lab in station_shapes]\n",
    "ax.legend(handles=legend_elements, loc='lower right', frameon=True, fontsize=14)\n",
    "\n",
    "\n",
    "# Sauvegarde\n",
    "save_path = r\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\plot\\10m\\Compared_Dataset_PSS_10m.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14abbacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# üîß Dictionnaire des datasets\n",
    "datasets = {\n",
    "    \"ICON-LAM\": metrics_ICON_df.copy(),\n",
    "    \"ERA5\": metrics_ERA5_df.copy(),\n",
    "    \"ERA5_GWA\": metrics_ERA5_GWA_df.copy()\n",
    "}\n",
    "\n",
    "# üîß Palette et ordre\n",
    "label_order = [\"SASSCALWN\", \"TAHMO\", \"NCEI\", \"ALL\"]\n",
    "palette = {\n",
    "    \"SASSCALWN\": \"#66c2a5\",\n",
    "    \"TAHMO\": \"gray\",\n",
    "    \"NCEI\": \"#8da0cb\",\n",
    "    \"ALL\": \"#e78ac3\"\n",
    "}\n",
    "\n",
    "# üîß M√©triques √† tracer\n",
    "metrics = {\n",
    "    \"MAE\": \"Mean Absolute Error (m/s)\"\n",
    "}\n",
    "\n",
    "# üîÅ Boucle sur chaque m√©trique\n",
    "for metric, metric_label in metrics.items():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 7), sharey=True)\n",
    "    plt.suptitle(f\"{metric_label} ‚Äì Dataset vs Observed at 10m\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    for ax, (ds_name, df) in zip(axes, datasets.items()):\n",
    "        # üîß Ajouter cat√©gorie ALL\n",
    "        df_all = df.copy()\n",
    "        df_all[\"label\"] = \"ALL\"\n",
    "        df_combined = pd.concat([df, df_all], ignore_index=True)\n",
    "\n",
    "        # üìä Boxplot\n",
    "        sns.boxplot(\n",
    "            data=df_combined,\n",
    "            x=\"label\", y=metric,\n",
    "            order=label_order,\n",
    "            palette=palette,\n",
    "            showfliers=False,\n",
    "            width=0.6,\n",
    "            boxprops=dict(linewidth=1.2, edgecolor='black'),\n",
    "            medianprops=dict(color=\"black\", linewidth=2),\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # üìç Points individuels\n",
    "        sns.stripplot(\n",
    "            data=df_combined,\n",
    "            x=\"label\", y=metric,\n",
    "            order=label_order,\n",
    "            color=\"orange\", size=5, alpha=0.6,\n",
    "            jitter=True,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # üìç Moyenne en ligne blanche pointill√©e + n\n",
    "        for i, label in enumerate(label_order):\n",
    "            vals = df_combined[df_combined[\"label\"] == label][metric].dropna()\n",
    "            if not vals.empty:\n",
    "                mean_val = vals.mean()\n",
    "                ax.hlines(mean_val, i - 0.2, i + 0.2, colors=\"white\", linestyles=\"--\", linewidth=2)\n",
    "                ax.text(i, vals.max() + 0.05 * abs(vals.max()), f\"n={len(vals)}\", ha=\"center\", fontsize=12)\n",
    "\n",
    "        ax.set_title(ds_name, fontsize=18)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"MAE(m/s)\", fontsize=16)\n",
    "        ax.set_xticklabels(label_order, rotation=20, fontsize=16)\n",
    "        ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    filename = f\"BoxPlot_GROUPED_10m_{metric.replace(' ', '_')}.png\"\n",
    "    save_path = rf\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\plot\\10m\\{filename}\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# üîß M√©triques √† tracer\n",
    "metrics = {\n",
    "    \"ME\": \"Mean Error (m/s)\"\n",
    "}\n",
    "\n",
    "# üîÅ Boucle sur chaque m√©trique\n",
    "for metric, metric_label in metrics.items():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 7), sharey=True)\n",
    "    plt.suptitle(f\"{metric_label} ‚Äì Dataset vs Observed at 10m\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    for ax, (ds_name, df) in zip(axes, datasets.items()):\n",
    "        # üîß Ajouter cat√©gorie ALL\n",
    "        df_all = df.copy()\n",
    "        df_all[\"label\"] = \"ALL\"\n",
    "        df_combined = pd.concat([df, df_all], ignore_index=True)\n",
    "\n",
    "        # üìä Boxplot\n",
    "        sns.boxplot(\n",
    "            data=df_combined,\n",
    "            x=\"label\", y=metric,\n",
    "            order=label_order,\n",
    "            palette=palette,\n",
    "            showfliers=False,\n",
    "            width=0.6,\n",
    "            boxprops=dict(linewidth=1.2, edgecolor='black'),\n",
    "            medianprops=dict(color=\"black\", linewidth=2),\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # üìç Points individuels\n",
    "        sns.stripplot(\n",
    "            data=df_combined,\n",
    "            x=\"label\", y=metric,\n",
    "            order=label_order,\n",
    "            color=\"orange\", size=5, alpha=0.6,\n",
    "            jitter=True,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # üìç Moyenne en ligne blanche pointill√©e + n\n",
    "        for i, label in enumerate(label_order):\n",
    "            vals = df_combined[df_combined[\"label\"] == label][metric].dropna()\n",
    "            if not vals.empty:\n",
    "                mean_val = vals.mean()\n",
    "                ax.hlines(mean_val, i - 0.2, i + 0.2, colors=\"white\", linestyles=\"--\", linewidth=2)\n",
    "                ax.text(i, vals.max() + 0.05 * abs(vals.max()), f\"n={len(vals)}\", ha=\"center\", fontsize=12)\n",
    "\n",
    "        ax.set_title(ds_name, fontsize=18)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"ME(m/s)\", fontsize=16)\n",
    "        ax.set_xticklabels(label_order, rotation=20, fontsize=16)\n",
    "        ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    filename = f\"BoxPlot_GROUPED_10m_{metric.replace(' ', '_')}.png\"\n",
    "    save_path = rf\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\plot\\10m\\{filename}\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# üîß M√©triques √† tracer\n",
    "metrics = {\n",
    "    \"Pearson r\": \"Pearson Correlation\"\n",
    "}\n",
    "\n",
    "# üîÅ Boucle sur chaque m√©trique\n",
    "for metric, metric_label in metrics.items():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 7), sharey=True)\n",
    "    plt.suptitle(f\"{metric_label} ‚Äì Dataset vs Observed at 10m\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    for ax, (ds_name, df) in zip(axes, datasets.items()):\n",
    "        # üîß Ajouter cat√©gorie ALL\n",
    "        df_all = df.copy()\n",
    "        df_all[\"label\"] = \"ALL\"\n",
    "        df_combined = pd.concat([df, df_all], ignore_index=True)\n",
    "\n",
    "        # üìä Boxplot\n",
    "        sns.boxplot(\n",
    "            data=df_combined,\n",
    "            x=\"label\", y=metric,\n",
    "            order=label_order,\n",
    "            palette=palette,\n",
    "            showfliers=False,\n",
    "            width=0.6,\n",
    "            boxprops=dict(linewidth=1.2, edgecolor='black'),\n",
    "            medianprops=dict(color=\"black\", linewidth=2),\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # üìç Points individuels\n",
    "        sns.stripplot(\n",
    "            data=df_combined,\n",
    "            x=\"label\", y=metric,\n",
    "            order=label_order,\n",
    "            color=\"orange\", size=5, alpha=0.6,\n",
    "            jitter=True,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # üìç Moyenne en ligne blanche pointill√©e + n\n",
    "        for i, label in enumerate(label_order):\n",
    "            vals = df_combined[df_combined[\"label\"] == label][metric].dropna()\n",
    "            if not vals.empty:\n",
    "                mean_val = vals.mean()\n",
    "                ax.hlines(mean_val, i - 0.2, i + 0.2, colors=\"white\", linestyles=\"--\", linewidth=2)\n",
    "                ax.text(i, vals.max() + 0.05 * abs(vals.max()), f\"n={len(vals)}\", ha=\"center\", fontsize=12)\n",
    "\n",
    "        ax.set_title(ds_name, fontsize=18)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"Pearson r[:]\", fontsize=16)\n",
    "        ax.set_xticklabels(label_order, rotation=20, fontsize=16)\n",
    "        ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    filename = f\"BoxPlot_GROUPED_10m_{metric.replace(' ', '_')}.png\"\n",
    "    save_path = rf\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\plot\\10m\\{filename}\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# üîß M√©triques √† tracer\n",
    "metrics = {\n",
    "    \"PSS\": \"Perkins Skill Score\"\n",
    "}\n",
    "\n",
    "# üîÅ Boucle sur chaque m√©trique\n",
    "for metric, metric_label in metrics.items():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 7), sharey=True)\n",
    "    plt.suptitle(f\"{metric_label} ‚Äì Dataset vs Observed at 10m\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    for ax, (ds_name, df) in zip(axes, datasets.items()):\n",
    "        # üîß Ajouter cat√©gorie ALL\n",
    "        df_all = df.copy()\n",
    "        df_all[\"label\"] = \"ALL\"\n",
    "        df_combined = pd.concat([df, df_all], ignore_index=True)\n",
    "\n",
    "        # üìä Boxplot\n",
    "        sns.boxplot(\n",
    "            data=df_combined,\n",
    "            x=\"label\", y=metric,\n",
    "            order=label_order,\n",
    "            palette=palette,\n",
    "            showfliers=False,\n",
    "            width=0.6,\n",
    "            boxprops=dict(linewidth=1.2, edgecolor='black'),\n",
    "            medianprops=dict(color=\"black\", linewidth=2),\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # üìç Points individuels\n",
    "        sns.stripplot(\n",
    "            data=df_combined,\n",
    "            x=\"label\", y=metric,\n",
    "            order=label_order,\n",
    "            color=\"orange\", size=5, alpha=0.6,\n",
    "            jitter=True,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # üìç Moyenne en ligne blanche pointill√©e + n\n",
    "        for i, label in enumerate(label_order):\n",
    "            vals = df_combined[df_combined[\"label\"] == label][metric].dropna()\n",
    "            if not vals.empty:\n",
    "                mean_val = vals.mean()\n",
    "                ax.hlines(mean_val, i - 0.2, i + 0.2, colors=\"white\", linestyles=\"--\", linewidth=2)\n",
    "                ax.text(i, vals.max() + 0.05 * abs(vals.max()), f\"n={len(vals)}\", ha=\"center\", fontsize=12)\n",
    "\n",
    "        ax.set_title(ds_name, fontsize=18)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"PSS[:]\", fontsize=16)\n",
    "        ax.set_xticklabels(label_order, rotation=20, fontsize=16)\n",
    "        ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    filename = f\"BoxPlot_GROUPED_10m_{metric.replace(' ', '_')}.png\"\n",
    "    save_path = rf\"C:\\Users\\LENOVO\\Downloads\\pyton trainning\\essais perso\\week 16\\Final coding\\plot\\10m\\{filename}\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd42afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdedab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d4bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91baa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (windsim)",
   "language": "python",
   "name": "windsim_py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
